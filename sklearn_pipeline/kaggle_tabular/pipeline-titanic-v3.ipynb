{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import interp\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer, PolynomialFeatures\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "from sklearn.metrics import plot_confusion_matrix, roc_auc_score,  auc, \\\n",
    "    precision_recall_fscore_support, classification_report, roc_curve, plot_roc_curve\n",
    "\n",
    "from sklearn import set_config\n",
    "set_config(display='diagram')   \n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "\n",
    "from itertools import cycle\n",
    "from time import time\n",
    "\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sub = pd.read_csv('data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Oconnor, Frankie</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>209245</td>\n",
       "      <td>27.14</td>\n",
       "      <td>C12239</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Bryan, Drew</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27323</td>\n",
       "      <td>13.35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Owens, Kenneth</td>\n",
       "      <td>male</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>CA 457703</td>\n",
       "      <td>71.29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Kramer, James</td>\n",
       "      <td>male</td>\n",
       "      <td>19.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A. 10866</td>\n",
       "      <td>13.04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Bond, Michael</td>\n",
       "      <td>male</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>427635</td>\n",
       "      <td>7.76</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>99995</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Bell, Adele</td>\n",
       "      <td>female</td>\n",
       "      <td>62.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 15008</td>\n",
       "      <td>14.86</td>\n",
       "      <td>D17243</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>99996</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Brown, Herman</td>\n",
       "      <td>male</td>\n",
       "      <td>66.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13273</td>\n",
       "      <td>11.15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>99997</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Childress, Charles</td>\n",
       "      <td>male</td>\n",
       "      <td>37.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.95</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>99998</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Caughlin, Thomas</td>\n",
       "      <td>male</td>\n",
       "      <td>51.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>458654</td>\n",
       "      <td>30.92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>99999</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Enciso, Tyler</td>\n",
       "      <td>male</td>\n",
       "      <td>55.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>458074</td>\n",
       "      <td>13.96</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId  Survived  Pclass                Name     Sex    Age  \\\n",
       "0                0         1       1    Oconnor, Frankie    male    NaN   \n",
       "1                1         0       3         Bryan, Drew    male    NaN   \n",
       "2                2         0       3      Owens, Kenneth    male   0.33   \n",
       "3                3         0       3       Kramer, James    male  19.00   \n",
       "4                4         1       3       Bond, Michael    male  25.00   \n",
       "...            ...       ...     ...                 ...     ...    ...   \n",
       "99995        99995         1       2         Bell, Adele  female  62.00   \n",
       "99996        99996         0       2       Brown, Herman    male  66.00   \n",
       "99997        99997         0       3  Childress, Charles    male  37.00   \n",
       "99998        99998         0       3    Caughlin, Thomas    male  51.00   \n",
       "99999        99999         0       3       Enciso, Tyler    male  55.00   \n",
       "\n",
       "       SibSp  Parch     Ticket   Fare   Cabin Embarked  \n",
       "0          2      0     209245  27.14  C12239        S  \n",
       "1          0      0      27323  13.35     NaN        S  \n",
       "2          1      2  CA 457703  71.29     NaN        S  \n",
       "3          0      0   A. 10866  13.04     NaN        S  \n",
       "4          0      0     427635   7.76     NaN        S  \n",
       "...      ...    ...        ...    ...     ...      ...  \n",
       "99995      0      0   PC 15008  14.86  D17243        C  \n",
       "99996      0      0      13273  11.15     NaN        S  \n",
       "99997      0      0        NaN   9.95     NaN        S  \n",
       "99998      0      1     458654  30.92     NaN        S  \n",
       "99999      0      0     458074  13.96     NaN        S  \n",
       "\n",
       "[100000 rows x 12 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100000</td>\n",
       "      <td>3</td>\n",
       "      <td>Holliday, Daniel</td>\n",
       "      <td>male</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24745</td>\n",
       "      <td>63.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100001</td>\n",
       "      <td>3</td>\n",
       "      <td>Nguyen, Lorraine</td>\n",
       "      <td>female</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13264</td>\n",
       "      <td>5.81</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100002</td>\n",
       "      <td>1</td>\n",
       "      <td>Harris, Heather</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25990</td>\n",
       "      <td>38.91</td>\n",
       "      <td>B15315</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100003</td>\n",
       "      <td>2</td>\n",
       "      <td>Larsen, Eric</td>\n",
       "      <td>male</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>314011</td>\n",
       "      <td>12.93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100004</td>\n",
       "      <td>1</td>\n",
       "      <td>Cleary, Sarah</td>\n",
       "      <td>female</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>26203</td>\n",
       "      <td>26.89</td>\n",
       "      <td>B22515</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>199995</td>\n",
       "      <td>3</td>\n",
       "      <td>Cash, Cheryle</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7686</td>\n",
       "      <td>10.12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>199996</td>\n",
       "      <td>1</td>\n",
       "      <td>Brown, Howard</td>\n",
       "      <td>male</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13004</td>\n",
       "      <td>68.31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>199997</td>\n",
       "      <td>3</td>\n",
       "      <td>Lightfoot, Cameron</td>\n",
       "      <td>male</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4383317</td>\n",
       "      <td>10.87</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>199998</td>\n",
       "      <td>1</td>\n",
       "      <td>Jacobsen, Margaret</td>\n",
       "      <td>female</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>PC 26988</td>\n",
       "      <td>29.68</td>\n",
       "      <td>B20828</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>199999</td>\n",
       "      <td>1</td>\n",
       "      <td>Fishback, Joanna</td>\n",
       "      <td>female</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>PC 41824</td>\n",
       "      <td>195.41</td>\n",
       "      <td>E13345</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId  Pclass                Name     Sex   Age  SibSp  Parch  \\\n",
       "0           100000       3    Holliday, Daniel    male  19.0      0      0   \n",
       "1           100001       3    Nguyen, Lorraine  female  53.0      0      0   \n",
       "2           100002       1     Harris, Heather  female  19.0      0      0   \n",
       "3           100003       2        Larsen, Eric    male  25.0      0      0   \n",
       "4           100004       1       Cleary, Sarah  female  17.0      0      2   \n",
       "...            ...     ...                 ...     ...   ...    ...    ...   \n",
       "99995       199995       3       Cash, Cheryle  female  27.0      0      0   \n",
       "99996       199996       1       Brown, Howard    male  59.0      1      0   \n",
       "99997       199997       3  Lightfoot, Cameron    male  47.0      0      0   \n",
       "99998       199998       1  Jacobsen, Margaret  female  49.0      1      2   \n",
       "99999       199999       1    Fishback, Joanna  female  41.0      0      2   \n",
       "\n",
       "         Ticket    Fare   Cabin Embarked  \n",
       "0         24745   63.01     NaN        S  \n",
       "1         13264    5.81     NaN        S  \n",
       "2         25990   38.91  B15315        C  \n",
       "3        314011   12.93     NaN        S  \n",
       "4         26203   26.89  B22515        C  \n",
       "...         ...     ...     ...      ...  \n",
       "99995      7686   10.12     NaN        Q  \n",
       "99996     13004   68.31     NaN        S  \n",
       "99997   4383317   10.87     NaN        S  \n",
       "99998  PC 26988   29.68  B20828        C  \n",
       "99999  PC 41824  195.41  E13345        C  \n",
       "\n",
       "[100000 rows x 11 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100002</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100003</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100004</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>199995</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>199996</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>199997</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>199998</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>199999</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId  Survived\n",
       "0           100000         1\n",
       "1           100001         1\n",
       "2           100002         1\n",
       "3           100003         1\n",
       "4           100004         1\n",
       "...            ...       ...\n",
       "99995       199995         1\n",
       "99996       199996         1\n",
       "99997       199997         1\n",
       "99998       199998         1\n",
       "99999       199999         1\n",
       "\n",
       "[100000 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_sub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>passengerid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Oconnor, Frankie</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>209245</td>\n",
       "      <td>27.14</td>\n",
       "      <td>C12239</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Bryan, Drew</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27323</td>\n",
       "      <td>13.35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Owens, Kenneth</td>\n",
       "      <td>male</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>CA 457703</td>\n",
       "      <td>71.29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Kramer, James</td>\n",
       "      <td>male</td>\n",
       "      <td>19.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A. 10866</td>\n",
       "      <td>13.04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Bond, Michael</td>\n",
       "      <td>male</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>427635</td>\n",
       "      <td>7.76</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             pclass              name   sex    age  sibsp  parch     ticket  \\\n",
       "passengerid                                                                   \n",
       "0                 1  Oconnor, Frankie  male    NaN      2      0     209245   \n",
       "1                 3       Bryan, Drew  male    NaN      0      0      27323   \n",
       "2                 3    Owens, Kenneth  male   0.33      1      2  CA 457703   \n",
       "3                 3     Kramer, James  male  19.00      0      0   A. 10866   \n",
       "4                 3     Bond, Michael  male  25.00      0      0     427635   \n",
       "\n",
       "              fare   cabin embarked  \n",
       "passengerid                          \n",
       "0            27.14  C12239        S  \n",
       "1            13.35     NaN        S  \n",
       "2            71.29     NaN        S  \n",
       "3            13.04     NaN        S  \n",
       "4             7.76     NaN        S  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = df_train[[col for col in df_train.columns if col != 'Survived']]\n",
    "X_train.columns = [c.lower() for c in X_train.columns]\n",
    "X_train.set_index('passengerid', inplace=True)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "passengerid\n",
       "0    1\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    1\n",
       "Name: survived, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = df_train[['PassengerId','Survived']]\n",
    "y_train.columns = [c.lower() for c in y_train.columns]\n",
    "y_train.set_index('passengerid', inplace=True)\n",
    "y_train = y_train['survived']\n",
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>passengerid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100000</th>\n",
       "      <td>3</td>\n",
       "      <td>Holliday, Daniel</td>\n",
       "      <td>male</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24745</td>\n",
       "      <td>63.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100001</th>\n",
       "      <td>3</td>\n",
       "      <td>Nguyen, Lorraine</td>\n",
       "      <td>female</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13264</td>\n",
       "      <td>5.81</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100002</th>\n",
       "      <td>1</td>\n",
       "      <td>Harris, Heather</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25990</td>\n",
       "      <td>38.91</td>\n",
       "      <td>B15315</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100003</th>\n",
       "      <td>2</td>\n",
       "      <td>Larsen, Eric</td>\n",
       "      <td>male</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>314011</td>\n",
       "      <td>12.93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100004</th>\n",
       "      <td>1</td>\n",
       "      <td>Cleary, Sarah</td>\n",
       "      <td>female</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>26203</td>\n",
       "      <td>26.89</td>\n",
       "      <td>B22515</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             pclass              name     sex   age  sibsp  parch  ticket  \\\n",
       "passengerid                                                                 \n",
       "100000            3  Holliday, Daniel    male  19.0      0      0   24745   \n",
       "100001            3  Nguyen, Lorraine  female  53.0      0      0   13264   \n",
       "100002            1   Harris, Heather  female  19.0      0      0   25990   \n",
       "100003            2      Larsen, Eric    male  25.0      0      0  314011   \n",
       "100004            1     Cleary, Sarah  female  17.0      0      2   26203   \n",
       "\n",
       "              fare   cabin embarked  \n",
       "passengerid                          \n",
       "100000       63.01     NaN        S  \n",
       "100001        5.81     NaN        S  \n",
       "100002       38.91  B15315        C  \n",
       "100003       12.93     NaN        S  \n",
       "100004       26.89  B22515        C  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = df_test[[col for col in df_test.columns if col != 'Survived']]\n",
    "X_test.columns = [c.lower() for c in X_test.columns]\n",
    "X_test.set_index('passengerid', inplace=True)\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pipeline simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_features = ['name', 'ticket']\n",
    "cat_features = ['sex', 'embarked', 'cabin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_features = X_train.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_name(df_base, col):\n",
    "    df = df_base[col].apply(lambda x: x.split(',')).to_frame('list_name')\n",
    "    df['surname'] = df['list_name'].apply(lambda x: x[0])\n",
    "    df['forename'] = df['list_name'].apply(lambda x: x[1])\n",
    "    return df[['surname', 'forename']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tck_str(tck):\n",
    "    try:\n",
    "        x = tck.split()\n",
    "        try: \n",
    "            a = int(x[0])\n",
    "            return None\n",
    "        except:\n",
    "            return x[0]\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "def get_tck_num(tck):\n",
    "    try:\n",
    "        x = tck.split()\n",
    "        try:\n",
    "            a = int(x[0])\n",
    "            return a\n",
    "        except:\n",
    "            return None\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def transform_ticket(df_base, col):\n",
    "    df_ticket = df_base[col].to_frame('ticket')\n",
    "    df_ticket['ticket_str'] = df_base[col].apply(get_tck_str)\n",
    "    df_ticket['ticket_num'] = df_base[col].apply(get_tck_num)\n",
    "    return df_ticket[['ticket_str', 'ticket_num']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_cabin(df_base, col):\n",
    "    df_cabin = df_base[col].to_frame('cabin')\n",
    "    df_cabin_clean = df_cabin[~df_cabin['cabin'].isna()].copy()\n",
    "    df_cabin_clean['cabin_str'] = df_cabin_clean['cabin'].apply(lambda x: x[0])\n",
    "    df_cabin_clean['cabin_num'] = df_cabin_clean['cabin'].apply(lambda x: x[1:]).astype(int)\n",
    "    return df_cabin.join(df_cabin_clean[['cabin_str', 'cabin_num']])[['cabin_str', 'cabin_num']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "class PassNameTransformer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        self.X = transform_name(X, 'name')\n",
    "        return self.X\n",
    "\n",
    "    # I have corrected the output here, See point 2\n",
    "    def get_feature_names(self):\n",
    "        return self.X.columns.tolist()\n",
    "\n",
    "class TicketTransformer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        self.X = transform_ticket(X, 'ticket')\n",
    "        return self.X\n",
    "\n",
    "    # I have corrected the output here, See point 2\n",
    "    def get_feature_names(self):\n",
    "        return self.X.columns.tolist()\n",
    "    \n",
    "class CabinTransformer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        self.X = transform_cabin(X, 'cabin')\n",
    "        return self.X\n",
    "\n",
    "    # I have corrected the output here, See point 2\n",
    "    def get_feature_names(self):\n",
    "        return self.X.columns.tolist()\n",
    "class ColumnSelectTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns=None):\n",
    "        super(ColumnSelectTransformer).__init__()\n",
    "        self.columns=columns\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_values(df):\n",
    "    o_features = df.dtypes[df.dtypes=='object'].index.to_list()\n",
    "    df_copy = df.copy()\n",
    "    for c in o_features:\n",
    "        df_copy[c] = df_copy[c].apply(lambda x: x.lower() if type(x)==str else None)\n",
    "    return df_copy\n",
    "class LowerTransformer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self,X):\n",
    "        return lower_values(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "class featureUnion(FeatureUnion):\n",
    "    def _hstack(self, Xs):\n",
    "        cols = [X.columns.tolist() for X in Xs]\n",
    "        dtypes = []\n",
    "        for X in Xs:\n",
    "            dtypes.append([str(X[col].dtype) for col in X])\n",
    "        cols = np.hstack(cols)\n",
    "        dtypes = np.hstack(dtypes)\n",
    "        data = pd.DataFrame(super()._hstack(Xs), columns = cols)\n",
    "        print('====Converting columns types====')\n",
    "        for col, dtype in tqdm(zip(cols, dtypes)):\n",
    "            data[col] = data[col].astype(dtype)\n",
    "        return data\n",
    "\n",
    "class columnTransformer(ColumnTransformer):\n",
    "    def _hstack(self, Xs):\n",
    "        cols = [X.columns.tolist() for X in Xs]\n",
    "        dtypes = []\n",
    "        print(cols)\n",
    "        print([X.shape for X in Xs])\n",
    "        for X in Xs:\n",
    "            dtypes.append([str(X[col].dtype) for col in X])\n",
    "        cols = np.hstack(cols)\n",
    "        dtypes = np.hstack(dtypes)\n",
    "        data = pd.DataFrame(super()._hstack(Xs), columns = cols)\n",
    "        print('====Converting columns types====')\n",
    "        for col, dtype in tqdm(zip(cols, dtypes)):\n",
    "            data[col] = data[col].astype(dtype)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_processor = featureUnion(transformer_list=[\n",
    "    ('pass_name', PassNameTransformer()),\n",
    "    ('ticket', TicketTransformer()),\n",
    "    ('cabin', CabinTransformer()),\n",
    "    ('others', ColumnSelectTransformer(columns=[c for c in original_features if c not in ('name', 'ticket', 'cabin')]))\n",
    "]\n",
    ")\n",
    "pl = Pipeline(steps=[\n",
    "    ('raw_data_processor', col_processor),\n",
    "    ('lower_text_values', LowerTransformer())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>div.sk-top-container {color: black;background-color: white;}div.sk-toggleable {background-color: white;}label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.2em 0.3em;box-sizing: border-box;text-align: center;}div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}div.sk-estimator {font-family: monospace;background-color: #f0f8ff;margin: 0.25em 0.25em;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;}div.sk-estimator:hover {background-color: #d4ebff;}div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;}div.sk-item {z-index: 1;}div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}div.sk-parallel-item:only-child::after {width: 0;}div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0.2em;box-sizing: border-box;padding-bottom: 0.1em;background-color: white;position: relative;}div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}div.sk-label-container {position: relative;z-index: 2;text-align: center;}div.sk-container {display: inline-block;position: relative;}</style><div class=\"sk-top-container\"><div class=\"sk-container\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"87a4b31e-79f7-43ff-ba30-9a21e6377b12\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"87a4b31e-79f7-43ff-ba30-9a21e6377b12\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[('raw_data_processor',\n",
       "                 featureUnion(transformer_list=[('pass_name',\n",
       "                                                 PassNameTransformer()),\n",
       "                                                ('ticket', TicketTransformer()),\n",
       "                                                ('cabin', CabinTransformer()),\n",
       "                                                ('others',\n",
       "                                                 ColumnSelectTransformer(columns=['pclass',\n",
       "                                                                                  'sex',\n",
       "                                                                                  'age',\n",
       "                                                                                  'sibsp',\n",
       "                                                                                  'parch',\n",
       "                                                                                  'fare',\n",
       "                                                                                  'embarked']))])),\n",
       "                ('lower_text_values', LowerTransformer())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"e0076ac5-86bc-4db6-b97b-fae075f6db2e\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"e0076ac5-86bc-4db6-b97b-fae075f6db2e\">raw_data_processor: featureUnion</label><div class=\"sk-toggleable__content\"><pre>featureUnion(transformer_list=[('pass_name', PassNameTransformer()),\n",
       "                               ('ticket', TicketTransformer()),\n",
       "                               ('cabin', CabinTransformer()),\n",
       "                               ('others',\n",
       "                                ColumnSelectTransformer(columns=['pclass',\n",
       "                                                                 'sex', 'age',\n",
       "                                                                 'sibsp',\n",
       "                                                                 'parch',\n",
       "                                                                 'fare',\n",
       "                                                                 'embarked']))])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>pass_name</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"62adad09-aa12-4bbf-8c52-7a2ceff8b6bf\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"62adad09-aa12-4bbf-8c52-7a2ceff8b6bf\">PassNameTransformer</label><div class=\"sk-toggleable__content\"><pre>PassNameTransformer()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>ticket</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"ce65611a-7040-4359-ba56-59a572425658\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"ce65611a-7040-4359-ba56-59a572425658\">TicketTransformer</label><div class=\"sk-toggleable__content\"><pre>TicketTransformer()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>cabin</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"307472cb-8d6e-42db-b85c-fd13885f4276\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"307472cb-8d6e-42db-b85c-fd13885f4276\">CabinTransformer</label><div class=\"sk-toggleable__content\"><pre>CabinTransformer()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>others</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"76ad590a-a34f-42fe-ae1b-d0ebee3e1fb0\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"76ad590a-a34f-42fe-ae1b-d0ebee3e1fb0\">ColumnSelectTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnSelectTransformer(columns=['pclass', 'sex', 'age', 'sibsp', 'parch',\n",
       "                                 'fare', 'embarked'])</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"3c43396e-74b8-4e59-a95e-188ca68b3045\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"3c43396e-74b8-4e59-a95e-188ca68b3045\">LowerTransformer</label><div class=\"sk-toggleable__content\"><pre>LowerTransformer()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('raw_data_processor',\n",
       "                 featureUnion(transformer_list=[('pass_name',\n",
       "                                                 PassNameTransformer()),\n",
       "                                                ('ticket', TicketTransformer()),\n",
       "                                                ('cabin', CabinTransformer()),\n",
       "                                                ('others',\n",
       "                                                 ColumnSelectTransformer(columns=['pclass',\n",
       "                                                                                  'sex',\n",
       "                                                                                  'age',\n",
       "                                                                                  'sibsp',\n",
       "                                                                                  'parch',\n",
       "                                                                                  'fare',\n",
       "                                                                                  'embarked']))])),\n",
       "                ('lower_text_values', LowerTransformer())])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Converting columns types====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d52f628f15344752b2ac180d02579db7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df2 = pl.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>surname</th>\n",
       "      <th>forename</th>\n",
       "      <th>ticket_str</th>\n",
       "      <th>ticket_num</th>\n",
       "      <th>cabin_str</th>\n",
       "      <th>cabin_num</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>oconnor</td>\n",
       "      <td>frankie</td>\n",
       "      <td>None</td>\n",
       "      <td>209245.0</td>\n",
       "      <td>c</td>\n",
       "      <td>12239.0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>27.14</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bryan</td>\n",
       "      <td>drew</td>\n",
       "      <td>None</td>\n",
       "      <td>27323.0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.35</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>owens</td>\n",
       "      <td>kenneth</td>\n",
       "      <td>ca</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>71.29</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kramer</td>\n",
       "      <td>james</td>\n",
       "      <td>a.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>19.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.04</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bond</td>\n",
       "      <td>michael</td>\n",
       "      <td>None</td>\n",
       "      <td>427635.0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.76</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>bell</td>\n",
       "      <td>adele</td>\n",
       "      <td>pc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>d</td>\n",
       "      <td>17243.0</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>62.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14.86</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>brown</td>\n",
       "      <td>herman</td>\n",
       "      <td>None</td>\n",
       "      <td>13273.0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>66.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11.15</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>childress</td>\n",
       "      <td>charles</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>37.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.95</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>caughlin</td>\n",
       "      <td>thomas</td>\n",
       "      <td>None</td>\n",
       "      <td>458654.0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>51.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>30.92</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>enciso</td>\n",
       "      <td>tyler</td>\n",
       "      <td>None</td>\n",
       "      <td>458074.0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>55.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.96</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         surname  forename ticket_str  ticket_num cabin_str  cabin_num  \\\n",
       "0        oconnor   frankie       None    209245.0         c    12239.0   \n",
       "1          bryan      drew       None     27323.0      None        NaN   \n",
       "2          owens   kenneth         ca         NaN      None        NaN   \n",
       "3         kramer     james         a.         NaN      None        NaN   \n",
       "4           bond   michael       None    427635.0      None        NaN   \n",
       "...          ...       ...        ...         ...       ...        ...   \n",
       "99995       bell     adele         pc         NaN         d    17243.0   \n",
       "99996      brown    herman       None     13273.0      None        NaN   \n",
       "99997  childress   charles       None         NaN      None        NaN   \n",
       "99998   caughlin    thomas       None    458654.0      None        NaN   \n",
       "99999     enciso     tyler       None    458074.0      None        NaN   \n",
       "\n",
       "       pclass     sex    age  sibsp  parch   fare embarked  \n",
       "0           1    male    NaN      2      0  27.14        s  \n",
       "1           3    male    NaN      0      0  13.35        s  \n",
       "2           3    male   0.33      1      2  71.29        s  \n",
       "3           3    male  19.00      0      0  13.04        s  \n",
       "4           3    male  25.00      0      0   7.76        s  \n",
       "...       ...     ...    ...    ...    ...    ...      ...  \n",
       "99995       2  female  62.00      0      0  14.86        c  \n",
       "99996       2    male  66.00      0      0  11.15        s  \n",
       "99997       3    male  37.00      0      0   9.95        s  \n",
       "99998       3    male  51.00      0      1  30.92        s  \n",
       "99999       3    male  55.00      0      0  13.96        s  \n",
       "\n",
       "[100000 rows x 13 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "class simpleImputer(SimpleImputer):\n",
    "    def fit(self, X, y=None):\n",
    "        self._cols = X.columns.tolist()\n",
    "        self._dtypes = [str(X[col].dtype) for col in X.columns]\n",
    "        super().fit(X, y)\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X):\n",
    "        X_ = super().transform(X)\n",
    "        data = pd.DataFrame(X_, columns = self._cols)\n",
    "        for col, dtype in tqdm(zip(self._cols, self._dtypes)):\n",
    "            data[col] = data[col].astype(dtype)\n",
    "        return data\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_handle_na = columnTransformer(\n",
    "    transformers=[\n",
    "        ('text_features', simpleImputer(missing_values=None, strategy='constant', fill_value='unk'), make_column_selector(dtype_include=['object'])),\n",
    "        ('float_features', simpleImputer(strategy='median'), make_column_selector(dtype_include=['float64'])),\n",
    "        ('count_features', simpleImputer(strategy='most_frequent'), make_column_selector(dtype_include=['int64']))\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_simple = Pipeline(steps=[\n",
    "    ('pl', pl),\n",
    "    ('null_handling', col_handle_na)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pl_simple.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PipelineLogger(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def log_start(self):\n",
    "        self.start_time = time()\n",
    "        print(f'======== {self.__class__.__name__} - START ========')\n",
    "        return None\n",
    "        \n",
    "    def log_finish(self):\n",
    "        self.duration = time() - self.start_time\n",
    "        print(f'======== {self.__class__.__name__} - FINISH =======> Take: {self.duration:.6f}(s)')\n",
    "\n",
    "\n",
    "class ExperimentBase(BaseEstimator):\n",
    "    def evaluate(self, X_test, y_test):\n",
    "        print('Evaluating model')\n",
    "        print(classification_report(y_true=y_test, y_pred=self.predict(X_test)))\n",
    "        metrics = self.auc_report(X_test, y_test)\n",
    "        metrics['precision'], metrics['recall'], metrics['f1_score'], metrics['support'] = precision_recall_fscore_support(y_test, self.predict(X_test))\n",
    "        return metrics\n",
    "    \n",
    "    def auc_report(self, X, y_true):\n",
    "        classes = self.classes_\n",
    "        y_pred_classes = self.predict_proba(X)\n",
    "        n_classes = len(classes)\n",
    "\n",
    "        lw = 2\n",
    "        for i in range(len(classes)):\n",
    "            print(f\"\"\"{classes[i]}: {roc_auc_score(y_true=(y_true==classes[i]).astype(int), y_score=y_pred_classes[:,i])}\"\"\")\n",
    "\n",
    "        # Compute ROC curve and ROC area for each class\n",
    "        fpr = dict()\n",
    "        tpr = dict()\n",
    "        roc_auc = dict()\n",
    "\n",
    "        for i in range(n_classes):\n",
    "            fpr[i], tpr[i], _ = roc_curve(y_true=(y_true==classes[i]).astype(int), y_score=y_pred_classes[:,i])\n",
    "            roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "        all_fpr = np.unique(np.concatenate([fpr[i] for i in range(len(classes))]))\n",
    "\n",
    "        # Then interpolate all ROC curves at this points\n",
    "        mean_tpr = np.zeros_like(all_fpr)\n",
    "        for i in range(len(classes)):\n",
    "            mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "        # Finally average it and compute AUC\n",
    "        mean_tpr /= n_classes\n",
    "\n",
    "        fpr[\"macro\"] = all_fpr\n",
    "        tpr[\"macro\"] = mean_tpr\n",
    "        roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "        # Plot all ROC curves\n",
    "        plt.figure()\n",
    "\n",
    "        plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "                 label='macro-average ROC curve (area = {0:0.2f})'\n",
    "                       ''.format(roc_auc[\"macro\"]),\n",
    "                 color='navy', linestyle=':', linewidth=4)\n",
    "\n",
    "        colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
    "        for i, color in zip(range(n_classes), colors):\n",
    "            plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "                     label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "                     ''.format(classes[i], roc_auc[i]))\n",
    "\n",
    "        plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('Some extension of Receiver operating characteristic to multi-class')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.show()\n",
    "        metrics = {\n",
    "            'macro_auc': roc_auc[\"macro\"]\n",
    "        }\n",
    "        for i in range(n_classes):\n",
    "            metrics[f'auc_{classes[i]}'] = roc_auc[i]\n",
    "        return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCatBoostClassifier(CatBoostClassifier, ExperimentBase, PipelineLogger):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "    def fit(self, X, y, self_evaluate=True, **kwargs):\n",
    "        self.log_start()\n",
    "        if self._init_params.get('cat_features') is not None:\n",
    "            cat_features_ = [c for c in self._init_params['cat_features'] if c in X.columns]\n",
    "            self._init_params['cat_features'] = cat_features_\n",
    "        else:\n",
    "            cat_features_ = None\n",
    "        if self._init_params.get('text_features') is not None:\n",
    "            text_features_ = [c for c in self._init_params['text_features'] if c in X.columns]\n",
    "            self._init_params['text_features'] = text_features_\n",
    "        else:\n",
    "            text_features_ = None\n",
    "        \n",
    "        X_t, X_e, y_t, y_e = self.train_eval_split(X, y, cat_features_, text_features_)\n",
    "        super().fit(X_t, y_t, eval_set=(X_e, y_e), cat_features=cat_features_, text_features=text_features_)\n",
    "        if self_evaluate:\n",
    "            _ = self.evaluate(X_e, y_e)\n",
    "        self.log_finish()\n",
    "        return self\n",
    "        \n",
    "    def train_eval_split(self, X, y, cat_features_, text_features_, eval_frac=0.1, add_na_Xy=False, na_label=0):\n",
    "        X_e = X.sample(frac=eval_frac, random_state=42)\n",
    "        y_e = y.loc[X_e.index]\n",
    "        X_t = X.drop(X_e.index)\n",
    "        y_t = y.loc[X_t.index]\n",
    "        if add_na_Xy:\n",
    "            X_t = pd.concat([X_t, pd.DataFrame([[np.nan] * X_t.shape[1]], columns=X_t.columns)], ignore_index=True)\n",
    "            y_t = pd.concat([y_t, pd.Series([na_label])], ignore_index=True)\n",
    "        if cat_features_ is not None:\n",
    "            cat_features_ = [c for c in cat_features_ if c in X.columns]\n",
    "            X_t[cat_features_] = X_t[cat_features_].fillna('unk')\n",
    "            X_e[cat_features_] = X_e[cat_features_].fillna('unk')\n",
    "        if text_features_ is not None:\n",
    "            text_features_ = [c for c in text_features_ if c in X.columns]\n",
    "            X_t[text_features_] = X_t[text_features_].fillna('unk')\n",
    "            X_e[text_features_] = X_e[text_features_].fillna('unk')\n",
    "        \n",
    "        return X_t, X_e, y_t, y_e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = ['ticket_str', 'cabin_str', 'embarked', 'sex'] + ['surname', 'forename']\n",
    "# text_features = \n",
    "cb_cfg = {\n",
    "    'iterations': 1000,\n",
    "    'task_type': 'CPU',\n",
    "    'cat_features': cat_features,\n",
    "#     'text_features': text_features,\n",
    "    'use_best_model': True,\n",
    "    'early_stopping_rounds':50,\n",
    "    'verbose': True,\n",
    "    'metric_period': 25\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl4 = Pipeline(steps=[\n",
    "    ('pl_simple', pl_simple),\n",
    "    ('catboost_simple', CustomCatBoostClassifier(**cb_cfg))\n",
    "])\n",
    "pl4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl4.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = pl4.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[['surname', 'forename', 'ticket_str', 'cabin_str', 'sex', 'embarked']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "class CustomLabelEncoder(PipelineLogger,TransformerMixin, BaseEstimator):\n",
    "    def __init__(self, columns=None):\n",
    "        super(CustomLabelEncoder).__init__()\n",
    "        self.columns = columns\n",
    "        self.label_encoders = {}\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        X_ = X[self.columns]\n",
    "        X_ = pd.concat([X_, pd.DataFrame([['unk'] * X_.shape[1]], columns=X_.columns)], ignore_index=True)\n",
    "        for c in self.columns:\n",
    "            self.label_encoders[c] = LabelEncoder().fit(X_[c])\n",
    "        print(self.label_encoders)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X_ = pd.DataFrame()\n",
    "        self.dummy_dicts = {}\n",
    "        for c in self.columns:\n",
    "            dd = {}\n",
    "            for cl in self.label_encoders[c].classes_:\n",
    "                dd[cl] = True\n",
    "            sr = X[c].map(lambda s: 'unk' if dd.get(s) is None else s)\n",
    "            X_[c] = self.label_encoders[c].transform(sr)\n",
    "        return X_\n",
    "            \n",
    "    def inverse_transform(self, X_encode, y=None):\n",
    "        X_decode = pd.DataFrame()\n",
    "        for c in self.columns:\n",
    "            X_decode[c] = self.label_encoders[c].inverse_transform(X_encode[c])\n",
    "        return X_decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mul_le = CustomLabelEncoder(\n",
    "        columns=['surname', 'forename', 'ticket_str', 'cabin_str', 'sex', 'embarked']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoding = columnTransformer(transformers=[\n",
    "    ('category_encoder', mul_le, ['surname', 'forename', 'ticket_str', 'cabin_str', 'sex', 'embarked'])\n",
    "], remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mul_le.fit_transform(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLGBMClassifier(ExperimentBase, LGBMClassifier):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_lgbm = Pipeline(steps=[\n",
    "    ('prepro', pl),\n",
    "    ('label_encoding', label_encoding),\n",
    "    ('lgbm', CustomLGBMClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_lgbm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_lgbm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pl_lgbm.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_train, a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = pl4.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(~(a == b)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_lgbm['lgbm'].feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import plot_importance as lgbm_importance\n",
    "lgbm_importance(pl_lgbm['lgbm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_lgbm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_ada = Pipeline(steps=[\n",
    "    ('prepro', pl),\n",
    "    ('label_encoding', label_encoding),\n",
    "    ('na_handler', col_handle_na),\n",
    "    ('ada', AdaBoostClassifier(n_estimators=300, learning_rate=0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_ada.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_ada.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_est_cb = Pipeline(steps=[\n",
    "    ('null_handling', deepcopy(col_handle_na)),\n",
    "    ('catboost_simple', CustomCatBoostClassifier(**cb_cfg))\n",
    "])\n",
    "pl_est_cb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl__cb_simple = Pipeline(steps=[\n",
    "    ('pl', pl),\n",
    "    ('pl_est_cb', pl_est_cb)\n",
    "])\n",
    "pl__cb_simple.fit(X_train, y_train)\n",
    "y_pred_cb = pl__cb_simple.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_est_lgbm = Pipeline(steps=[\n",
    "    ('label_encoding', deepcopy(label_encoding)),\n",
    "    ('lgbm', CustomLGBMClassifier())\n",
    "])\n",
    "pl_est_lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl__lgbm = Pipeline(steps=[\n",
    "    ('pl', pl),\n",
    "    ('pl_est_lgbm', pl_est_lgbm)\n",
    "])\n",
    "pl__lgbm.fit(X_train, y_train)\n",
    "y_pred_lgbm = pl__lgbm.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_est_ada = Pipeline(steps=[\n",
    "    ('label_encoding', deepcopy(label_encoding)),\n",
    "    ('na_handler', deepcopy(col_handle_na)),\n",
    "    ('ada', AdaBoostClassifier(n_estimators=300, learning_rate=0.5))\n",
    "])\n",
    "pl_est_ada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl__ada = Pipeline(steps=[\n",
    "    ('pl', pl),\n",
    "    ('pl_est_ada', pl_est_ada)\n",
    "])\n",
    "pl__ada.fit(X_train, y_train)\n",
    "y_pred_ada = pl__ada.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ensemble_3_trees = ((y_pred_cb + y_pred_lgbm + y_pred_ada) > 1.5).astype(int)\n",
    "y_ensemble_3_trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_pred = X_test[['name']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_pred['cb_simple'] = pl__cb_simple.predict(X_test)\n",
    "Y_test_pred[[f\"cb_simple_{x}\" for x in pl__cb_simple['pl_est_cb']['catboost_simple'].classes_]] = \\\n",
    "pl__cb_simple.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_pred['lgbm'] = pl__lgbm.predict(X_test)\n",
    "Y_test_pred[[f\"lgbm_{x}\" for x in pl__lgbm['pl_est_lgbm']['lgbm'].classes_]] = \\\n",
    "pl__lgbm.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_pred['ada'] = pl__ada.predict(X_test)\n",
    "Y_test_pred[[f\"ada_{x}\" for x in pl__ada['pl_est_ada']['ada'].classes_]] = \\\n",
    "pl__ada.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_pred['voting_hard'] = ((Y_test_pred['cb_simple'] + Y_test_pred['lgbm'] + Y_test_pred['ada']) > 1.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_pred['voting_soft'] = ((Y_test_pred['cb_simple_1'] + Y_test_pred['lgbm_1'] + Y_test_pred['ada_1']) > 1.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_pred[Y_test_pred['voting_hard']!=Y_test_pred['voting_soft']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm4 = Y_test_pred['cb_simple'].to_frame().reset_index().rename(columns={'passengerid':'PassengerId', 'cb_simple':'Survived'})\n",
    "sm4.to_csv('sm__cb_simple.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm5 = Y_test_pred['voting_soft'].to_frame('survived').reset_index().rename(columns={'passengerid':'PassengerId', 'survived':'Survived'})\n",
    "sm5.to_csv('sm__voting_soft_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred['Survived'] = y_ensemble_3_trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Y_pred['Survived'].to_frame().reset_index()\n",
    "m.columns = ['PassengerId', 'Survived']\n",
    "\n",
    "m.to_csv('submission_v2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_pred = X_train[['name']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_pred['y_true'] = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_pred['cb_simple'] = pl__cb_simple.predict(X_train)\n",
    "Y_train_pred[[f\"cb_simple_{x}\" for x in pl__cb_simple['pl_est_cb']['catboost_simple'].classes_]] = \\\n",
    "pl__cb_simple.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_pred['lgbm'] = pl__lgbm.predict(X_train)\n",
    "Y_train_pred[[f\"lgbm_{x}\" for x in pl__lgbm['pl_est_lgbm']['lgbm'].classes_]] = \\\n",
    "pl__lgbm.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_pred['ada'] = pl__ada.predict(X_train)\n",
    "Y_train_pred[[f\"ada_{x}\" for x in pl__ada['pl_est_ada']['ada'].classes_]] = \\\n",
    "pl__ada.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_pred.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_pred[Y_train_pred['cb_simple'] == Y_train_pred['lgbm']].groupby('cb_simple')['cb_simple_1']\\\n",
    ".agg(['min', 'max', 'mean', 'median', 'std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_pred[Y_train_pred['cb_simple'] != Y_train_pred['lgbm']].groupby('cb_simple')['cb_simple_1']\\\n",
    ".agg(['min', 'max', 'mean', 'median', 'std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_pred[Y_train_pred['cb_simple'] == Y_train_pred['lgbm']].groupby('lgbm')['lgbm_1']\\\n",
    ".agg(['min', 'max', 'mean', 'median', 'std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_pred[Y_train_pred['cb_simple'] != Y_train_pred['lgbm']].groupby('lgbm')['lgbm_1']\\\n",
    ".agg(['min', 'max', 'mean', 'median', 'std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_pred['voting_hard'] = ((Y_train_pred['cb_simple'] + Y_train_pred['lgbm'] + Y_train_pred['ada']) > 1.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_pred['voting_soft'] = ((Y_train_pred['cb_simple_1'] + Y_train_pred['lgbm_1'] + Y_train_pred['ada_1']) > 1.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = Y_train_pred[Y_train_pred['voting_hard'] != Y_train_pred['voting_soft']]\n",
    "(b['voting_hard'] == b['y_true']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(b['voting_soft'] == b['y_true']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(Y_train_pred['y_true'], Y_train_pred['voting_hard']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(Y_train_pred['y_true'], Y_train_pred['voting_soft']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_pred['cb_simple'] = pl__cb_simple.predict(X_train)\n",
    "Y_train_pred[[f\"cb_simple_{x}\" for x in pl__cb_simple['pl_est_cb']['catboost_simple'].classes_]] = \\\n",
    "pl__cb_simple.predict_proba(X_train)\n",
    "Y_train_pred['lgbm'] = pl__lgbm.predict(X_train)\n",
    "Y_train_pred[[f\"lgbm_{x}\" for x in pl__lgbm['pl_est_lgbm']['lgbm'].classes_]] = \\\n",
    "pl__lgbm.predict_proba(X_train)\n",
    "Y_train_pred['ada'] = pl__ada.predict(X_train)\n",
    "Y_train_pred[[f\"ada_{x}\" for x in pl__ada['pl_est_ada']['ada'].classes_]] = \\\n",
    "pl__ada.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to submit catboost simple to see if it outperform \n",
    "m = Y_pred['Survived'].to_frame().reset_index()\n",
    "m.columns = ['PassengerId', 'Survived']\n",
    "\n",
    "m.to_csv('submission_v2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Catboost Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = pd.concat([X_train, X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Converting columns types====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "437ef33e2b904857949c1fd6e2590982",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df2 = pl.fit_transform(X_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>surname</th>\n",
       "      <th>forename</th>\n",
       "      <th>ticket_str</th>\n",
       "      <th>ticket_num</th>\n",
       "      <th>cabin_str</th>\n",
       "      <th>cabin_num</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>oconnor</td>\n",
       "      <td>frankie</td>\n",
       "      <td>None</td>\n",
       "      <td>209245.0</td>\n",
       "      <td>c</td>\n",
       "      <td>12239.0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>27.14</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bryan</td>\n",
       "      <td>drew</td>\n",
       "      <td>None</td>\n",
       "      <td>27323.0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.35</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>owens</td>\n",
       "      <td>kenneth</td>\n",
       "      <td>ca</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>71.29</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kramer</td>\n",
       "      <td>james</td>\n",
       "      <td>a.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>19.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.04</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bond</td>\n",
       "      <td>michael</td>\n",
       "      <td>None</td>\n",
       "      <td>427635.0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.76</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>cash</td>\n",
       "      <td>cheryle</td>\n",
       "      <td>None</td>\n",
       "      <td>7686.0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>27.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.12</td>\n",
       "      <td>q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>brown</td>\n",
       "      <td>howard</td>\n",
       "      <td>None</td>\n",
       "      <td>13004.0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>59.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>68.31</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>lightfoot</td>\n",
       "      <td>cameron</td>\n",
       "      <td>None</td>\n",
       "      <td>4383317.0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>47.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.87</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>jacobsen</td>\n",
       "      <td>margaret</td>\n",
       "      <td>pc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>b</td>\n",
       "      <td>20828.0</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>49.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>29.68</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>fishback</td>\n",
       "      <td>joanna</td>\n",
       "      <td>pc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>e</td>\n",
       "      <td>13345.0</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>41.00</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>195.41</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          surname   forename ticket_str  ticket_num cabin_str  cabin_num  \\\n",
       "0         oconnor    frankie       None    209245.0         c    12239.0   \n",
       "1           bryan       drew       None     27323.0      None        NaN   \n",
       "2           owens    kenneth         ca         NaN      None        NaN   \n",
       "3          kramer      james         a.         NaN      None        NaN   \n",
       "4            bond    michael       None    427635.0      None        NaN   \n",
       "...           ...        ...        ...         ...       ...        ...   \n",
       "199995       cash    cheryle       None      7686.0      None        NaN   \n",
       "199996      brown     howard       None     13004.0      None        NaN   \n",
       "199997  lightfoot    cameron       None   4383317.0      None        NaN   \n",
       "199998   jacobsen   margaret         pc         NaN         b    20828.0   \n",
       "199999   fishback     joanna         pc         NaN         e    13345.0   \n",
       "\n",
       "        pclass     sex    age  sibsp  parch    fare embarked  \n",
       "0            1    male    NaN      2      0   27.14        s  \n",
       "1            3    male    NaN      0      0   13.35        s  \n",
       "2            3    male   0.33      1      2   71.29        s  \n",
       "3            3    male  19.00      0      0   13.04        s  \n",
       "4            3    male  25.00      0      0    7.76        s  \n",
       "...        ...     ...    ...    ...    ...     ...      ...  \n",
       "199995       3  female  27.00      0      0   10.12        q  \n",
       "199996       1    male  59.00      1      0   68.31        s  \n",
       "199997       3    male  47.00      0      0   10.87        s  \n",
       "199998       1  female  49.00      1      2   29.68        c  \n",
       "199999       1  female  41.00      0      2  195.41        c  \n",
       "\n",
       "[200000 rows x 13 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor, CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_unk(sr):\n",
    "    return sr.fillna('unk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_mean(sr):\n",
    "    return sr.fillna(sr.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_0(sr):\n",
    "    return sr.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_popular(sr):\n",
    "    popular = sr.value_counts().index[0]\n",
    "    return sr.fillna(popular)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pc': 1.0,\n",
       " 'a.': 1.298597870231504,\n",
       " 'c.a.': 1.5657620862440709,\n",
       " 'sc/paris': 1.8380554509089366,\n",
       " 'ston/o': 1.8894533171027126,\n",
       " 'a/5.': 2.185284861311075,\n",
       " 'a/5': 2.234059204823897,\n",
       " 'pp': 2.2491340279863996,\n",
       " 'soton/o.q.': 2.2734889936742184,\n",
       " 'w./c.': 2.27527282276212,\n",
       " 'f.c.c.': 2.41385944154945,\n",
       " 'sc/ah': 2.539093689228038,\n",
       " 's.o.c.': 2.573622157663341,\n",
       " 'ca.': 2.6897859011757315,\n",
       " 'ston/o2.': 2.8026576818025823,\n",
       " 'a/4': 2.8026576818025823,\n",
       " 's.c./paris': 3.0198711076275746,\n",
       " 's.o./p.p.': 3.042580570368284,\n",
       " 'soton/o2': 3.0638830614016856,\n",
       " 'f.c.': 3.0813997867156724,\n",
       " 'c': 3.120116910258576,\n",
       " 'soton/oq': 3.178575350659462,\n",
       " 'ca': 3.2673873902403923,\n",
       " 'w.e.p.': 3.2935550331876913,\n",
       " 'we/p': 3.3845342463709795,\n",
       " 'sc': 3.571303920489865,\n",
       " 'a./5.': 3.6884017547174666,\n",
       " 'a/4.': 3.6884017547174666,\n",
       " 'p/pp': 3.9008817403085616,\n",
       " 'a.5.': 4.303013360334782,\n",
       " 'sco/w': 4.3813903923044935,\n",
       " 'aq/4': 4.5350231939195655,\n",
       " 'sc/a4': 4.72921289032816,\n",
       " 'lp': 4.881082091712631,\n",
       " 'sc/a.3': 5.0566380530632005,\n",
       " 'a/s': 5.219021857856507,\n",
       " 'c.a./soton': 5.381642664366629,\n",
       " 'ston/oq.': 5.458475405346789,\n",
       " 's.p.': 5.485167753113695,\n",
       " 'fa': 5.54029973627712,\n",
       " 's.w./pp': 5.568785200667665,\n",
       " 's.c./a.4.': 5.6277196763903925,\n",
       " 'sw/pp': 5.65822297508019,\n",
       " 'so/c': 5.65822297508019,\n",
       " 's.o.p.': 5.857739316890651,\n",
       " 'aq/3.': 5.89408634125259,\n",
       " 'w/c': 6.049967779420817,\n",
       " 'a4.': 6.425369603425045}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((df2['ticket_str'].value_counts().max() / df2['ticket_str'].value_counts()) ** 0.3).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'c': 1.0,\n",
       " 'b': 1.0588542033595938,\n",
       " 'a': 1.104304059955087,\n",
       " 'd': 1.398106110707252,\n",
       " 'e': 1.6443298990431572,\n",
       " 'f': 1.7371811100708827,\n",
       " 'g': 2.77587393719455,\n",
       " 't': 5.666875105902016}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((df2['cabin_str'].value_counts().max() / df2['cabin_str'].value_counts()) ** 0.3).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "impute_plan = {\n",
    "    'features_plan': {\n",
    "        'fare': {\n",
    "            'model': CatBoostRegressor,\n",
    "            'predictors': [c for c in df2.columns if c not in ['fare']],\n",
    "            'catboost_kwgs': {'iterations':200}\n",
    "        },\n",
    "        'embarked': {\n",
    "            'model': CatBoostClassifier,\n",
    "            'predictors': [c for c in df2.columns if c not in ['embarked']],\n",
    "            'catboost_kwgs': {'iterations': 200}\n",
    "        },\n",
    "        'age': {\n",
    "            'model': CatBoostRegressor,\n",
    "            'predictors': [c for c in df2.columns if c not in ['age']],\n",
    "            'catboost_kwgs': {'iterations': 200}\n",
    "        },\n",
    "        'ticket_num':{\n",
    "            'model': CatBoostRegressor,\n",
    "            'predictors': [c for c in df2.columns if c not in ['age']],\n",
    "            'catboost_kwgs': {'iterations': 200}\n",
    "        },\n",
    "        'ticket_str':{\n",
    "            'model': CatBoostClassifier,\n",
    "            'predictors': [c for c in df2.columns if c not in ['embarked']],\n",
    "            'catboost_kwgs': {\n",
    "                'iterations': 200, \n",
    "                'class_weights': ((df2['ticket_str'].value_counts().max() / df2['ticket_str'].value_counts()) ** 0.3).to_dict()\n",
    "            }\n",
    "        },\n",
    "        'cabin_num':{\n",
    "            'model': CatBoostRegressor,\n",
    "            'predictors': [c for c in df2.columns if c not in ['age']],\n",
    "            'catboost_kwgs': {\n",
    "                'iterations': 200\n",
    "            }\n",
    "        },\n",
    "        'cabin_str':{\n",
    "            'model': CatBoostClassifier,\n",
    "            'predictors': [c for c in df2.columns if c not in ['embarked']],\n",
    "            'catboost_kwgs': {\n",
    "                'iterations': 200,\n",
    "                'class_weights': ((df2['cabin_str'].value_counts().max() / df2['cabin_str'].value_counts()) ** 0.3).to_dict()\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    'if_na': {\n",
    "        'ticket_str':fill_unk,\n",
    "        'ticket_num':fill_mean,\n",
    "        'cabin_str':fill_unk,\n",
    "        'cabin_num':fill_mean,\n",
    "        'age':fill_mean,\n",
    "        'embarked':fill_popular,\n",
    "        'fare': fill_mean\n",
    "    },\n",
    "    'eval_frac': 0.1,\n",
    "    'cat_features': ['surname', 'forename', 'ticket_str', 'cabin_str', 'sex', 'embarked']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class CatBoostImputor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, impute_plan, predictors_order):\n",
    "        super(CatBoostImputor).__init__()\n",
    "        self.impute_plan = impute_plan\n",
    "        self.predictors_order = predictors_order\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def train_eval_test_split(self, x, y):\n",
    "        eval_frac = self.impute_plan['eval_frac']\n",
    "        y_test = y[y.isna()].copy()\n",
    "        x_test = x[y.isna()].copy()\n",
    "        x_t = x[~y.isna()].copy()\n",
    "        y_t = y[~y.isna()].copy()\n",
    "        x_train, x_eval, y_train, y_eval = train_test_split(x_t, y_t, test_size=eval_frac)\n",
    "        return x_train, y_train, x_eval, y_eval, x_test, y_test\n",
    "        \n",
    "    def transform(self, X):\n",
    "        self.X = X\n",
    "        self.X_impute = X.copy()\n",
    "        for col in self.predictors_order:\n",
    "            predictor_list = self.impute_plan['features_plan'][col]['predictors']\n",
    "            cat_features=[c for c in predictor_list if c in self.impute_plan['cat_features']]\n",
    "            # Prepare data to fit\n",
    "            print(f'Prepare data to fit, feature: {col}')\n",
    "            x = self.X_impute[predictor_list].copy()\n",
    "            y = self.X_impute[col]\n",
    "            na_cols = [col for col in x.columns if x[col].isna().sum() > 0]\n",
    "            for c in na_cols:\n",
    "                x[c] = self.impute_plan['if_na'][c](x[c])\n",
    "            x_train, y_train, x_eval, y_eval, x_test, y_test = self.train_eval_test_split(x, y)\n",
    "            \n",
    "            # Create model\n",
    "            ModelClass = self.impute_plan['features_plan'][col]['model']\n",
    "            model = ModelClass(**self.impute_plan['features_plan'][col]['catboost_kwgs'], early_stopping_rounds=50, verbose=True, metric_period=50, use_best_model=True)\n",
    "            # Fit model\n",
    "            print(f'Fit model: {col}')\n",
    "            model.fit(x_train, y_train, eval_set=(x_eval, y_eval), cat_features=cat_features)\n",
    "            x_test[col] = model.predict(x_test)\n",
    "            print(f'Predicted for {x_test.shape[0]} unknown examples')\n",
    "            self.X_impute.loc[y.isna(),col] = x_test[col]\n",
    "            print(f'Imputed done for {col}')\n",
    "        print(f'Imputed done for all dataset, num null left: {self.X_impute.isna().sum()}')\n",
    "        return self.X_impute\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbi = CatBoostImputor(impute_plan, ['fare', 'embarked', 'age', 'ticket_num', 'ticket_str', 'cabin_num', 'cabin_str'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepare data to fit, feature: fare\n",
      "Fit model: fare\n",
      "Learning rate set to 0.335029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 59.4983218\ttest: 59.0623694\tbest: 59.0623694 (0)\ttotal: 120ms\tremaining: 24s\n",
      "50:\tlearn: 51.1302180\ttest: 51.3088347\tbest: 51.2533689 (30)\ttotal: 2.15s\tremaining: 6.28s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 51.25336889\n",
      "bestIteration = 30\n",
      "\n",
      "Shrink model to first 31 iterations.\n",
      "Predicted for 267 unknown examples\n",
      "Imputed done for fare\n",
      "Prepare data to fit, feature: embarked\n",
      "Fit model: embarked\n",
      "Learning rate set to 0.221522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9278676\ttest: 0.9279810\tbest: 0.9279810 (0)\ttotal: 127ms\tremaining: 25.3s\n",
      "50:\tlearn: 0.6115885\ttest: 0.6189250\tbest: 0.6189250 (50)\ttotal: 5.61s\tremaining: 16.4s\n",
      "100:\tlearn: 0.6037331\ttest: 0.6143046\tbest: 0.6143046 (100)\ttotal: 11.1s\tremaining: 10.8s\n",
      "150:\tlearn: 0.5990681\ttest: 0.6127092\tbest: 0.6127092 (150)\ttotal: 16.5s\tremaining: 5.34s\n",
      "199:\tlearn: 0.5960023\ttest: 0.6125794\tbest: 0.6124769 (165)\ttotal: 22s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.6124768675\n",
      "bestIteration = 165\n",
      "\n",
      "Shrink model to first 166 iterations.\n",
      "Predicted for 527 unknown examples\n",
      "Imputed done for embarked\n",
      "Prepare data to fit, feature: age\n",
      "Fit model: age\n",
      "Learning rate set to 0.332936\n",
      "0:\tlearn: 16.0280617\ttest: 16.0313075\tbest: 16.0313075 (0)\ttotal: 45.8ms\tremaining: 9.11s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50:\tlearn: 15.0491609\ttest: 15.1258605\tbest: 15.1258605 (50)\ttotal: 2.25s\tremaining: 6.57s\n",
      "100:\tlearn: 14.9914318\ttest: 15.1162922\tbest: 15.1162922 (100)\ttotal: 4.15s\tremaining: 4.07s\n",
      "150:\tlearn: 14.9450624\ttest: 15.1128036\tbest: 15.1100615 (130)\ttotal: 6.16s\tremaining: 2s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 15.11006153\n",
      "bestIteration = 130\n",
      "\n",
      "Shrink model to first 131 iterations.\n",
      "Predicted for 6779 unknown examples\n",
      "Imputed done for age\n",
      "Prepare data to fit, feature: ticket_num\n",
      "Fit model: ticket_num\n",
      "Learning rate set to 0.313478\n",
      "0:\tlearn: 594225.5709626\ttest: 581641.5007189\tbest: 581641.5007189 (0)\ttotal: 36ms\tremaining: 7.16s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50:\tlearn: 81206.5906139\ttest: 78712.1527370\tbest: 78712.1527370 (50)\ttotal: 1.48s\tremaining: 4.31s\n",
      "100:\tlearn: 74345.6317695\ttest: 77874.1743259\tbest: 77170.3001097 (94)\ttotal: 2.89s\tremaining: 2.83s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 77170.30011\n",
      "bestIteration = 94\n",
      "\n",
      "Shrink model to first 95 iterations.\n",
      "Predicted for 59501 unknown examples\n",
      "Imputed done for ticket_num\n",
      "Prepare data to fit, feature: ticket_str\n",
      "Fit model: ticket_str\n",
      "Learning rate set to 0.21545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1.8275040\ttest: 1.8544913\tbest: 1.8544913 (0)\ttotal: 5.11s\tremaining: 16m 56s\n",
      "50:\tlearn: 0.0534475\ttest: 0.0335655\tbest: 0.0335655 (50)\ttotal: 5m 43s\tremaining: 16m 44s\n",
      "100:\tlearn: 0.0300609\ttest: 0.0204671\tbest: 0.0204671 (100)\ttotal: 12m 13s\tremaining: 11m 59s\n",
      "150:\tlearn: 0.0198630\ttest: 0.0149170\tbest: 0.0149170 (150)\ttotal: 18m 26s\tremaining: 5m 59s\n",
      "199:\tlearn: 0.0141246\ttest: 0.0109911\tbest: 0.0109911 (199)\ttotal: 24m 21s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.01099113226\n",
      "bestIteration = 199\n",
      "\n",
      "Predicted for 150303 unknown examples\n",
      "Imputed done for ticket_str\n",
      "Prepare data to fit, feature: cabin_num\n",
      "Fit model: cabin_num\n",
      "Learning rate set to 0.267997\n",
      "0:\tlearn: 4263.7101042\ttest: 4267.5842280\tbest: 4267.5842280 (0)\ttotal: 21.6ms\tremaining: 4.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50:\tlearn: 101.3957593\ttest: 101.6658688\tbest: 101.6658688 (50)\ttotal: 856ms\tremaining: 2.5s\n",
      "100:\tlearn: 56.9070749\ttest: 56.5507879\tbest: 56.5507879 (100)\ttotal: 1.7s\tremaining: 1.67s\n",
      "150:\tlearn: 42.3045591\ttest: 41.8517287\tbest: 41.8517287 (150)\ttotal: 2.5s\tremaining: 811ms\n",
      "199:\tlearn: 36.2012512\ttest: 36.3492558\tbest: 36.3492558 (199)\ttotal: 3.29s\tremaining: 0us\n",
      "\n",
      "bestTest = 36.34925582\n",
      "bestIteration = 199\n",
      "\n",
      "Predicted for 138697 unknown examples\n",
      "Imputed done for cabin_num\n",
      "Prepare data to fit, feature: cabin_str\n",
      "Fit model: cabin_str\n",
      "Learning rate set to 0.216356\n",
      "0:\tlearn: 0.8203747\ttest: 0.8217365\tbest: 0.8217365 (0)\ttotal: 139ms\tremaining: 27.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50:\tlearn: 0.0012447\ttest: 0.0010260\tbest: 0.0010260 (50)\ttotal: 8.67s\tremaining: 25.3s\n",
      "100:\tlearn: 0.0004766\ttest: 0.0003763\tbest: 0.0003763 (100)\ttotal: 17.3s\tremaining: 17s\n",
      "150:\tlearn: 0.0003139\ttest: 0.0002468\tbest: 0.0002468 (150)\ttotal: 26.1s\tremaining: 8.46s\n",
      "199:\tlearn: 0.0001953\ttest: 0.0001493\tbest: 0.0001493 (199)\ttotal: 34.6s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.000149295075\n",
      "bestIteration = 199\n",
      "\n",
      "Predicted for 138697 unknown examples\n",
      "Imputed done for cabin_str\n",
      "Imputed done for all dataset, num null left: surname       0\n",
      "forename      0\n",
      "ticket_str    0\n",
      "ticket_num    0\n",
      "cabin_str     0\n",
      "cabin_num     0\n",
      "pclass        0\n",
      "sex           0\n",
      "age           0\n",
      "sibsp         0\n",
      "parch         0\n",
      "fare          0\n",
      "embarked      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "imputed_X_all = cbi.fit_transform(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_X_all.to_parquet('data/imputed_X_all.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_t, X_train_e, y_train_t, y_train_e = train_test_split(clean_X_train, y_train, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_clean = CatBoostClassifier(iterations=1000, cat_features=['surname', 'forename', 'ticket_str', 'cabin_str', 'sex', 'embarked'], \n",
    "                                 early_stopping_rounds=50, verbose=True, metric_period=50, use_best_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_clean.fit(X_train_t, y_train_t, eval_set = (X_train_e, y_train_e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_e_pred = model_clean.predict(X_train_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_train_e, model_clean.predict(X_train_e)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_train_t, model_clean.predict(X_train_t)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ft_imp(model):\n",
    "    fi = pd.DataFrame({\n",
    "        'feature':X_train_e.columns,\n",
    "        'importance': model.feature_importances_\n",
    "    })\n",
    "\n",
    "    return fi.sort_values(by='importance',ascending=False).iloc[:50].style.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_imp(model_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_2 = pl.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbi_test = CatBoostImputor(impute_plan, ['fare', 'embarked', 'age', 'ticket_num', 'ticket_str', 'cabin_num', 'cabin_str'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_clean = cbi_test.fit_transform(X_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_clean.to_parquet('data/clean_X_test.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_2.ticket_num.hist(bins=50)\n",
    "plt.show()\n",
    "X_test_clean.ticket_num.hist(bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_2.cabin_num.hist(bins=50)\n",
    "plt.show()\n",
    "X_test_clean.cabin_num.hist(bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_2.age.hist(bins=50)\n",
    "plt.show()\n",
    "X_test_clean.age.hist(bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_2.cabin_str.value_counts()[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_clean.cabin_str.value_counts()[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extent pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impute_plan2 = deepcopy(impute_plan)\n",
    "wgt = 0\n",
    "impute_plan2['features_plan']['ticket_str']['catboost_kwgs']['class_weights'] = ((df2['ticket_str'].value_counts().max() / df2['ticket_str'].value_counts()) ** wgt).to_dict()\n",
    "impute_plan2['features_plan']['cabin_str']['catboost_kwgs']['class_weights'] = ((df2['cabin_str'].value_counts().max() / df2['cabin_str'].value_counts()) ** wgt).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl3 = Pipeline(steps = [\n",
    "    ('aaa', pl), \n",
    "    ('catboost_imputor', CatBoostImputor(impute_plan2,  ['fare', 'embarked', 'age', 'ticket_num', 'ticket_str', 'cabin_num', 'cabin_str']))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl2 = Pipeline(steps=[\n",
    "    ('raw_data_processor', col_processor),\n",
    "    ('lower_text_values', LowerTransformer()),\n",
    "    ('catboost_imputor', CatBoostImputor(impute_plan2,  ['fare', 'embarked', 'age', 'ticket_num', 'ticket_str', 'cabin_num', 'cabin_str']))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_X_train2 = pl2.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl2.__class__.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = CatBoostImputor(impute_plan, predictors_order=['fare', 'embarked', 'age', 'ticket_num', 'ticket_str', 'cabin_num', 'cabin_str'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.__class__.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.__class__.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CatBoostImputor.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time, sleep\n",
    "class PipelineLogger:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def log_start(self):\n",
    "        self.start_time = time()\n",
    "        print(f'======== {self.__class__.__name__} - START ========')\n",
    "        return None\n",
    "        \n",
    "    def log_finish(self):\n",
    "        self.duration = time() - self.start_time\n",
    "        print(f'======== {self.__class__.__name__} - FINISH =======> Take: {self.duration:.6f}(s)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JustSleep(PipelineLogger):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def sleep(self):\n",
    "        self.log_start()\n",
    "        sleep(1)\n",
    "        self.log_finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "js = JustSleep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "js.sleep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl += Pipeline(steps=[('catboost_imputor', CatBoostImputor(impute_plan,  ['fare', 'embarked', 'age', 'ticket_num', 'ticket_str', 'cabin_num', 'cabin_str']))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Catboost without fillna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_fillsimple = df2.copy()\n",
    "X_train_fillsimple[['ticket_str', 'cabin_str', 'embarked']] = X_train_fillsimple[['ticket_str', 'cabin_str', 'embarked']].fillna('unk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_fs_t, X_train_fs_e, y_train_fs_t, y_train_fs_e = train_test_split(X_train_fillsimple, y_train, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fs = CatBoostClassifier(iterations=1000, cat_features=['surname', 'forename', 'ticket_str', 'cabin_str', 'sex', 'embarked'], \n",
    "                                 early_stopping_rounds=50, verbose=True, metric_period=50, use_best_model=True, auto_class_weights=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fs.fit(X_train_fs_t, y_train_fs_t, eval_set = (X_train_fs_e, y_train_fs_e), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_fillsimple = X_test_2.copy()\n",
    "X_test_fillsimple[['ticket_str', 'cabin_str', 'embarked']] = X_test_fillsimple[['ticket_str', 'cabin_str', 'embarked']].fillna('unk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_train_fs_t, model_fs.predict(X_train_fs_t)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_train_fs_e, model_fs.predict(X_train_fs_e)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_fillsimple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_imp(model_fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model based on catboost imputed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['Survived'] = model_clean.predict(X_test_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = X_test['Survived'].to_frame().reset_index()\n",
    "m.columns = ['PassengerId', 'Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.to_csv('submission/v1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model based on simple imputed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['Survived_0_2'] = model_fs.predict(X_test_fillsimple)\n",
    "m = X_test['Survived_0_2'].to_frame().reset_index()\n",
    "m.columns = ['PassengerId', 'Survived']\n",
    "m.to_csv('submission/v0_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
